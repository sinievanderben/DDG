{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ship ML Experiment\n",
    "Predict gross tonnage of a ship! \n",
    "\n",
    "The approach can be divided into a few parts:\n",
    "1. Explore the dataset and prepare the data \n",
    "2. Create new features \n",
    "3. Separate the data into train, validation and test set\n",
    "4. Test feature importance \n",
    "5. Find correct algorithm and Hyperparameter tuning\n",
    "7. Test the algorithm \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But first: import all necessary packages for the start of this ML project!\n",
    "Some packages will be installed later, when necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1a: explore the dataset \n",
    "First I explore the dataset a bit. Although the set is small and column names and the number of rows can be seen immediately, I also get numeric values, type of the columns etc. Useful information for manual creation of features. \n",
    "\n",
    "I read in the data as a pandas dataframe. A dataframe allows for easy data exploration and data handling (column deletion, insertion etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        Ship_name Cruise_line  Age  cabins   crew  passengers  length  \\\n",
       "0        Journey     Azamara    6    3.55   3.55        6.94    5.94   \n",
       "1          Quest     Azamara    6    3.55   3.55        6.94    5.94   \n",
       "2    Celebration    Carnival   26    7.43   6.70       14.86    7.22   \n",
       "3       Conquest    Carnival   11   14.88  19.10       29.74    9.53   \n",
       "4        Destiny    Carnival   17   13.21  10.00       26.42    8.92   \n",
       "..           ...         ...  ...     ...    ...         ...     ...   \n",
       "153       Taurus        Star   22    0.33   0.59        0.66    2.79   \n",
       "154        Virgo        Star   14    9.67  12.00       19.60    8.79   \n",
       "155       Spirit    Windstar   25    0.74   0.88        1.58    4.40   \n",
       "156         Star    Windstar   27    0.74   0.88        1.67    4.40   \n",
       "157         Surf    Windstar   23    1.56   1.80        3.08    6.17   \n",
       "\n",
       "     passenger_density  gross_tonnage  \n",
       "0                42.64         30.277  \n",
       "1                42.64         30.277  \n",
       "2                31.80         47.262  \n",
       "3                36.99        110.000  \n",
       "4                38.36        101.353  \n",
       "..                 ...            ...  \n",
       "153              50.62          3.341  \n",
       "154              39.18         76.800  \n",
       "155              33.86          5.350  \n",
       "156              32.04          5.350  \n",
       "157              47.87         14.745  \n",
       "\n",
       "[158 rows x 9 columns]>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ship_data.csv\", skiprows= 0)\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ship_name</th>\n",
       "      <th>Cruise_line</th>\n",
       "      <th>Age</th>\n",
       "      <th>cabins</th>\n",
       "      <th>crew</th>\n",
       "      <th>passengers</th>\n",
       "      <th>length</th>\n",
       "      <th>passenger_density</th>\n",
       "      <th>gross_tonnage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Ship_name, Cruise_line, Age, cabins, crew, passengers, length, passenger_density, gross_tonnage]\n",
       "Index: []"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values \n",
    "data[data.isnull().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ship_name', 'Cruise_line', 'Age', 'cabins', 'crew', 'passengers',\n",
       "       'length', 'passenger_density', 'gross_tonnage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column names \n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158 entries, 0 to 157\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Ship_name          158 non-null    object \n",
      " 1   Cruise_line        158 non-null    object \n",
      " 2   Age                158 non-null    int64  \n",
      " 3   cabins             158 non-null    float64\n",
      " 4   crew               158 non-null    float64\n",
      " 5   passengers         158 non-null    float64\n",
      " 6   length             158 non-null    float64\n",
      " 7   passenger_density  158 non-null    float64\n",
      " 8   gross_tonnage      158 non-null    float64\n",
      "dtypes: float64(6), int64(1), object(2)\n",
      "memory usage: 11.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Information on number of columns, column types, number of rows\n",
    "data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>cabins</th>\n",
       "      <th>crew</th>\n",
       "      <th>passengers</th>\n",
       "      <th>length</th>\n",
       "      <th>passenger_density</th>\n",
       "      <th>gross_tonnage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.689873</td>\n",
       "      <td>8.830000</td>\n",
       "      <td>7.794177</td>\n",
       "      <td>18.457405</td>\n",
       "      <td>8.130633</td>\n",
       "      <td>39.900949</td>\n",
       "      <td>71.284671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.615691</td>\n",
       "      <td>4.471417</td>\n",
       "      <td>3.503487</td>\n",
       "      <td>9.677095</td>\n",
       "      <td>1.793474</td>\n",
       "      <td>8.639217</td>\n",
       "      <td>37.229540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>2.790000</td>\n",
       "      <td>17.700000</td>\n",
       "      <td>2.329000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.132500</td>\n",
       "      <td>5.480000</td>\n",
       "      <td>12.535000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>34.570000</td>\n",
       "      <td>46.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.570000</td>\n",
       "      <td>8.150000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>8.555000</td>\n",
       "      <td>39.085000</td>\n",
       "      <td>71.899000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.885000</td>\n",
       "      <td>9.990000</td>\n",
       "      <td>24.845000</td>\n",
       "      <td>9.510000</td>\n",
       "      <td>44.185000</td>\n",
       "      <td>90.772500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>11.820000</td>\n",
       "      <td>71.430000</td>\n",
       "      <td>220.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age      cabins        crew  passengers      length  \\\n",
       "count  158.000000  158.000000  158.000000  158.000000  158.000000   \n",
       "mean    15.689873    8.830000    7.794177   18.457405    8.130633   \n",
       "std      7.615691    4.471417    3.503487    9.677095    1.793474   \n",
       "min      4.000000    0.330000    0.590000    0.660000    2.790000   \n",
       "25%     10.000000    6.132500    5.480000   12.535000    7.100000   \n",
       "50%     14.000000    9.570000    8.150000   19.500000    8.555000   \n",
       "75%     20.000000   10.885000    9.990000   24.845000    9.510000   \n",
       "max     48.000000   27.000000   21.000000   54.000000   11.820000   \n",
       "\n",
       "       passenger_density  gross_tonnage  \n",
       "count         158.000000     158.000000  \n",
       "mean           39.900949      71.284671  \n",
       "std             8.639217      37.229540  \n",
       "min            17.700000       2.329000  \n",
       "25%            34.570000      46.013000  \n",
       "50%            39.085000      71.899000  \n",
       "75%            44.185000      90.772500  \n",
       "max            71.430000     220.000000  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More information in numbers of the numeric columns. 'Name' is excluded \n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional information with help from the internet:\n",
    "- Lenght is in foot (roughly 0.3 meters) x 100\n",
    "- Number of passengers is x 100\n",
    "- Number of crew is x 100\n",
    "- Number of cabins is x 10 \n",
    "- Passenger density the number of people per tonnage (so actually just passengers x passenger density = gross_tonnage?)\n",
    "- Gross tonnage is x 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1b: prepare the data \n",
    "Before I'll split into train, validation and test set, I have to prepare some features. As we can see in the data, there are numeric features as well as object features. \n",
    "\n",
    "One of the features is the name of the ship. Assuming the name is not of importance to the prediction of the gross tonnage, we can leave this feature out of the data. \n",
    "\n",
    "Another feature is the \"Cruise_line\". This might be an important feature, but we do not know that now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = ['Ship_name']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Cruise_line\"].unique()\n",
    "len(data[\"Cruise_line\"].unique()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 20 unique values for \"Cruise_line\". I will make this categorical using Label Encoding. This makes it easier for the model to handle, however it will lose some form of meaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cruise_line'] = data.Cruise_line.astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      Cruise_line  Age  cabins   crew  passengers  length  passenger_density  \\\n",
       "0              0    6    3.55   3.55        6.94    5.94              42.64   \n",
       "1              0    6    3.55   3.55        6.94    5.94              42.64   \n",
       "2              1   26    7.43   6.70       14.86    7.22              31.80   \n",
       "3              1   11   14.88  19.10       29.74    9.53              36.99   \n",
       "4              1   17   13.21  10.00       26.42    8.92              38.36   \n",
       "..           ...  ...     ...    ...         ...     ...                ...   \n",
       "153           18   22    0.33   0.59        0.66    2.79              50.62   \n",
       "154           18   14    9.67  12.00       19.60    8.79              39.18   \n",
       "155           19   25    0.74   0.88        1.58    4.40              33.86   \n",
       "156           19   27    0.74   0.88        1.67    4.40              32.04   \n",
       "157           19   23    1.56   1.80        3.08    6.17              47.87   \n",
       "\n",
       "     gross_tonnage  \n",
       "0           30.277  \n",
       "1           30.277  \n",
       "2           47.262  \n",
       "3          110.000  \n",
       "4          101.353  \n",
       "..             ...  \n",
       "153          3.341  \n",
       "154         76.800  \n",
       "155          5.350  \n",
       "156          5.350  \n",
       "157         14.745  \n",
       "\n",
       "[158 rows x 8 columns]>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X and y to start with \n",
    "X = data.drop(columns = ['gross_tonnage']).copy()\n",
    "y = data['gross_tonnage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Create new features\n",
    "As we expect and will see later, some of the features in the dataset are important for prediction of the gross tonnage, while other features are not. \n",
    "\n",
    "To make better predictions based on features, combinations of existing features might be predictors of the gross tonnage as well. \n",
    "\n",
    "Manually engineering features to improve the prediction power of the models:\n",
    "- Passenger per cabin  \n",
    "- Cabins per length \n",
    "- Passengers per length\n",
    "- Total number of people by adding crew and passengers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cruise_line</th>\n",
       "      <th>Age</th>\n",
       "      <th>cabins</th>\n",
       "      <th>crew</th>\n",
       "      <th>passengers</th>\n",
       "      <th>length</th>\n",
       "      <th>passenger_density</th>\n",
       "      <th>passenger_per_cabin</th>\n",
       "      <th>length_per_cabin</th>\n",
       "      <th>passengers_per_length</th>\n",
       "      <th>total_people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.55</td>\n",
       "      <td>6.94</td>\n",
       "      <td>5.94</td>\n",
       "      <td>42.64</td>\n",
       "      <td>5.115274</td>\n",
       "      <td>0.597643</td>\n",
       "      <td>0.855908</td>\n",
       "      <td>10.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.55</td>\n",
       "      <td>6.94</td>\n",
       "      <td>5.94</td>\n",
       "      <td>42.64</td>\n",
       "      <td>5.115274</td>\n",
       "      <td>0.597643</td>\n",
       "      <td>0.855908</td>\n",
       "      <td>10.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>7.43</td>\n",
       "      <td>6.70</td>\n",
       "      <td>14.86</td>\n",
       "      <td>7.22</td>\n",
       "      <td>31.80</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.029086</td>\n",
       "      <td>0.485868</td>\n",
       "      <td>21.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>14.88</td>\n",
       "      <td>19.10</td>\n",
       "      <td>29.74</td>\n",
       "      <td>9.53</td>\n",
       "      <td>36.99</td>\n",
       "      <td>5.003362</td>\n",
       "      <td>1.561385</td>\n",
       "      <td>0.320444</td>\n",
       "      <td>48.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>13.21</td>\n",
       "      <td>10.00</td>\n",
       "      <td>26.42</td>\n",
       "      <td>8.92</td>\n",
       "      <td>38.36</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.480942</td>\n",
       "      <td>0.337623</td>\n",
       "      <td>36.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.66</td>\n",
       "      <td>2.79</td>\n",
       "      <td>50.62</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.118280</td>\n",
       "      <td>4.227273</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>9.67</td>\n",
       "      <td>12.00</td>\n",
       "      <td>19.60</td>\n",
       "      <td>8.79</td>\n",
       "      <td>39.18</td>\n",
       "      <td>4.933673</td>\n",
       "      <td>1.100114</td>\n",
       "      <td>0.448469</td>\n",
       "      <td>31.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.58</td>\n",
       "      <td>4.40</td>\n",
       "      <td>33.86</td>\n",
       "      <td>4.683544</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>2.784810</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.40</td>\n",
       "      <td>32.04</td>\n",
       "      <td>4.431138</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>2.634731</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.08</td>\n",
       "      <td>6.17</td>\n",
       "      <td>47.87</td>\n",
       "      <td>5.064935</td>\n",
       "      <td>0.252836</td>\n",
       "      <td>2.003247</td>\n",
       "      <td>4.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cruise_line  Age  cabins   crew  passengers  length  passenger_density  \\\n",
       "0              0    6    3.55   3.55        6.94    5.94              42.64   \n",
       "1              0    6    3.55   3.55        6.94    5.94              42.64   \n",
       "2              1   26    7.43   6.70       14.86    7.22              31.80   \n",
       "3              1   11   14.88  19.10       29.74    9.53              36.99   \n",
       "4              1   17   13.21  10.00       26.42    8.92              38.36   \n",
       "..           ...  ...     ...    ...         ...     ...                ...   \n",
       "153           18   22    0.33   0.59        0.66    2.79              50.62   \n",
       "154           18   14    9.67  12.00       19.60    8.79              39.18   \n",
       "155           19   25    0.74   0.88        1.58    4.40              33.86   \n",
       "156           19   27    0.74   0.88        1.67    4.40              32.04   \n",
       "157           19   23    1.56   1.80        3.08    6.17              47.87   \n",
       "\n",
       "     passenger_per_cabin  length_per_cabin  passengers_per_length  \\\n",
       "0               5.115274          0.597643               0.855908   \n",
       "1               5.115274          0.597643               0.855908   \n",
       "2               5.000000          1.029086               0.485868   \n",
       "3               5.003362          1.561385               0.320444   \n",
       "4               5.000000          1.480942               0.337623   \n",
       "..                   ...               ...                    ...   \n",
       "153             5.000000          0.118280               4.227273   \n",
       "154             4.933673          1.100114               0.448469   \n",
       "155             4.683544          0.168182               2.784810   \n",
       "156             4.431138          0.168182               2.634731   \n",
       "157             5.064935          0.252836               2.003247   \n",
       "\n",
       "     total_people  \n",
       "0           10.49  \n",
       "1           10.49  \n",
       "2           21.56  \n",
       "3           48.84  \n",
       "4           36.42  \n",
       "..            ...  \n",
       "153          1.25  \n",
       "154         31.60  \n",
       "155          2.46  \n",
       "156          2.55  \n",
       "157          4.88  \n",
       "\n",
       "[158 rows x 11 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passenger per cabin \n",
    "# Cabins x 10\n",
    "# Passengers x 100\n",
    "# Length is in foot? Foot = 0.3 meter x 100\n",
    "for i in range(158):\n",
    "    X[\"passenger_per_cabin\"] = X[\"cabins\"] / (X[\"passengers\"] / 10)\n",
    "    X[\"length_per_cabin\"] = X[\"cabins\"] / X[\"length\"]\n",
    "    X[\"passengers_per_length\"] = X[\"length\"] / X[\"passengers\"]\n",
    "    X[\"total_people\"] = X[\"crew\"] + X[\"passengers\"]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cruise_line', 'Age', 'cabins', 'crew', 'passengers', 'length',\n",
       "       'passenger_density', 'passenger_per_cabin', 'length_per_cabin',\n",
       "       'passengers_per_length', 'total_people'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: split into train, validation and test set\n",
    "Train and test split as the usual practice, and addition of the validation set for the hyperparameter tuning. I opted for a small validation and test set, as the dataset has only 157 rows with data. \n",
    "\n",
    "Even though not completely necessary in a notebook, I've created a small function to return train, val and test set easily. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainValTest(X, y, train_part, val_part):\n",
    "\n",
    "    X_train, X_rest, y_train, y_rest = train_test_split(X,y, train_size=train_part)\n",
    "\n",
    "    test_part = 1 - train_part - val_part\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_rest,y_rest, test_size=test_part)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = getTrainValTest(X,y, 0.8, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: find feature importance \n",
    "From the given list of columns, not all features will be equally important. Keeping all features might result in overfitting, which is why some features are not taken into account for the training of the classifier. \n",
    "\n",
    "First we try to get a baseline with 2 different models by using all features and then use a function to calculate their feature importance.\n",
    "\n",
    "I opted for Linear regression, Random Forests and Support Vector Machines to get a quick and dirty indication of the possibly important features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for this part \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR  \n",
    "\n",
    "feat_names = ['Cruise_line', 'Age', 'cabins', 'crew', 'passengers', 'length',\n",
    "       'passenger_density', 'passenger_per_cabin', 'length_per_cabin',\n",
    "       'passengers_per_length', 'total_people']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=['Cruise_line', 'Age', 'cabins', 'crew', 'passengers', 'length',\n",
    "       'passenger_density', 'passenger_per_cabin', 'length_per_cabin',\n",
    "       'passengers_per_length', 'total_people']) \n",
    "\n",
    "scaled_X_val = pd.DataFrame(scaler.fit_transform(X_val), columns=['Cruise_line', 'Age', 'cabins', 'crew', 'passengers', 'length',\n",
    "       'passenger_density', 'passenger_per_cabin', 'length_per_cabin',\n",
    "       'passengers_per_length', 'total_people']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Cruise_line, Score: -0.5510592612092914\n",
      "Feature: 1, Age, Score: -0.6944541159918618\n",
      "Feature: 2, cabins, Score: 29.263596047365585\n",
      "Feature: 3, crew, Score: -0.15378009826429553\n",
      "Feature: 4, passengers, Score: 6.596920832484599\n",
      "Feature: 5, length, Score: 4.650177715398121\n",
      "Feature: 6, passenger_density, Score: 6.611007494292089\n",
      "Feature: 7, passenger_per_cabin, Score: -2.374451838019215\n",
      "Feature: 8, length_per_cabin, Score: -11.13346787185478\n",
      "Feature: 9, passengers_per_length, Score: -0.7743186550755403\n",
      "Feature: 10, total_people, Score: 4.86284581912719\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.fit(scaled_X_train, y_train)\n",
    "\n",
    "importance = model.coef_\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: {0}, {1}, Score: {2}'.format(i, feat_names[i],v))\n",
    "\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change line\n",
    "From this we can see that feature 2,4 and 5 are important, but feature 3 and 6 are close. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Cruise_line, Score: 0.004343064514168986\n",
      "Feature: 1, Age, Score: 0.010212672360212536\n",
      "Feature: 2, cabins, Score: 0.07554126484608455\n",
      "Feature: 3, crew, Score: 0.04134816379195951\n",
      "Feature: 4, passengers, Score: 0.1684688434377763\n",
      "Feature: 5, length, Score: 0.30054311098308667\n",
      "Feature: 6, passenger_density, Score: 0.0031158860408643306\n",
      "Feature: 7, passenger_per_cabin, Score: 0.0008405410642579354\n",
      "Feature: 8, length_per_cabin, Score: 0.025870520375018656\n",
      "Feature: 9, passengers_per_length, Score: 0.006058208481516929\n",
      "Feature: 10, total_people, Score: 0.36365772410505354\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "importance = model.feature_importances_\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: {0}, {1}, Score: {2}'.format(i, feat_names[i],v))\n",
    "\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature 2: cabins\n",
    "- Feature 5: length \n",
    "- Feature 10: total_people\n",
    "These feature using a RF seem to have the highest feature importance. Passenger_per_cabin and passenger_density seem to have the lowest feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Cruise_line, Score: 0.00047504149633749914\n",
      "Feature: 1, Age, Score: 0.007185409802998157\n",
      "Feature: 2, cabins, Score: 0.007006824616006689\n",
      "Feature: 3, crew, Score: 0.028466253260267912\n",
      "Feature: 4, passengers, Score: 0.11359284735575463\n",
      "Feature: 5, length, Score: 0.2888625252877303\n",
      "Feature: 6, passenger_density, Score: 0.005510911268012426\n",
      "Feature: 7, passenger_per_cabin, Score: 0.0001505593038129248\n",
      "Feature: 8, length_per_cabin, Score: 0.00867009898269599\n",
      "Feature: 9, passengers_per_length, Score: 0.0026006136973148563\n",
      "Feature: 10, total_people, Score: 0.5374789149290685\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "importance = model.feature_importances_\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: {0}, {1}, Score: {2}'.format(i, feat_names[i],v))\n",
    "\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"passengers\", \"cabins\" and \"length\" seem to have the highest correlation with the output value, while \"passengers_per_length\" and \"Age\" the lowest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So although the feature importance seems similar for both models, they might depend on the model used. Further analysis is necessary, but we might carefully say that number of cabins, number of passengers and length are important feature for determination of the output value, while cruise line and age are less important. \n",
    "\n",
    "####NOTE: \n",
    "It is actually quite interesting, because passenger_density * passengers gives gross tonnage, which is why I've expected that passengers and passenger_density both had higher feature importances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Features: to stay or to go?\n",
    "As the name of the ship does not really matter for the classification (well, maybe it does after extensive search of keywords?), we can leave out this column. A similar thing can be said about age. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try automatic selection of features using a Linear Regression classifier as baseline.  Instead of the test set, we use the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X_train, y_train, X_val, number):\n",
    "\t# configure to select a subset of features\n",
    "\tfs = SelectKBest(score_func=f_regression, k=number)\n",
    "\t# learn relationship from training data\n",
    "\tfs.fit(X_train, y_train)\n",
    "\t# transform train input data\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\t# transform test input data\n",
    "\tX_val_fs = fs.transform(X_val)\n",
    "\treturn X_train_fs, X_val_fs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Best features are for number  1  are:  Index(['total_people'], dtype='object')\n",
      "RMSE: 9.894\n",
      "Best features are for number  2  are:  Index(['passengers', 'total_people'], dtype='object')\n",
      "RMSE: 9.476\n",
      "Best features are for number  3  are:  Index(['cabins', 'passengers', 'total_people'], dtype='object')\n",
      "RMSE: 9.351\n",
      "Best features are for number  4  are:  Index(['cabins', 'passengers', 'length', 'total_people'], dtype='object')\n",
      "RMSE: 10.050\n",
      "Best features are for number  5  are:  Index(['cabins', 'crew', 'passengers', 'length', 'total_people'], dtype='object')\n",
      "RMSE: 10.050\n",
      "Best features are for number  6  are:  Index(['cabins', 'crew', 'passengers', 'length', 'length_per_cabin',\n",
      "       'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 5.880\n",
      "Best features are for number  7  are:  Index(['cabins', 'crew', 'passengers', 'length', 'length_per_cabin',\n",
      "       'passengers_per_length', 'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 5.927\n",
      "Best features are for number  8  are:  Index(['Age', 'cabins', 'crew', 'passengers', 'length', 'length_per_cabin',\n",
      "       'passengers_per_length', 'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 5.480\n",
      "Best features are for number  9  are:  Index(['Cruise_line', 'Age', 'cabins', 'crew', 'passengers', 'length',\n",
      "       'length_per_cabin', 'passengers_per_length', 'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 5.476\n",
      "Best features are for number  10  are:  Index(['Cruise_line', 'Age', 'cabins', 'crew', 'passengers', 'length',\n",
      "       'passenger_per_cabin', 'length_per_cabin', 'passengers_per_length',\n",
      "       'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 5.465\n",
      "Best features are for number  11  are:  Index(['Cruise_line', 'Age', 'cabins', 'crew', 'passengers', 'length',\n",
      "       'passenger_density', 'passenger_per_cabin', 'length_per_cabin',\n",
      "       'passengers_per_length', 'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 5.584\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression\")\n",
    "\n",
    "for i in range(1, 12):\n",
    "\n",
    "\tX_train_fs, X_val_fs, fs = select_features(X_train, y_train, X_val, i)\n",
    "\n",
    "\tmodel = LinearRegression()\n",
    "\tmodel.fit(X_train_fs, y_train)\n",
    "\n",
    "\tyhat = model.predict(X_val_fs)\n",
    "\n",
    "\t# Get the names of the features\n",
    "\tfilter = fs.get_support()\n",
    "\tfeatures = X_train.columns\n",
    "\n",
    "\tprint(\"Best features are for number \", i, \" are: \", features[filter])\n",
    "\trmse = mean_squared_error(y_val, yhat, squared=False)\n",
    "\tprint('RMSE: %.3f' % rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performance LR: 10 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Best features are for number  1  are:  Index(['total_people'], dtype='object')\n",
      "RMSE: 16.663\n",
      "Best features are for number  2  are:  Index(['passengers', 'total_people'], dtype='object')\n",
      "RMSE: 15.732\n",
      "Best features are for number  3  are:  Index(['cabins', 'passengers', 'total_people'], dtype='object')\n",
      "RMSE: 14.416\n",
      "Best features are for number  4  are:  Index(['cabins', 'passengers', 'length', 'total_people'], dtype='object')\n",
      "RMSE: 13.022\n",
      "Best features are for number  5  are:  Index(['cabins', 'crew', 'passengers', 'length', 'total_people'], dtype='object')\n",
      "RMSE: 13.124\n",
      "Best features are for number  6  are:  Index(['cabins', 'crew', 'passengers', 'length', 'length_per_cabin',\n",
      "       'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 12.892\n",
      "Best features are for number  7  are:  Index(['cabins', 'crew', 'passengers', 'length', 'length_per_cabin',\n",
      "       'passengers_per_length', 'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 12.864\n",
      "Best features are for number  8  are:  Index(['Age', 'cabins', 'crew', 'passengers', 'length', 'length_per_cabin',\n",
      "       'passengers_per_length', 'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 12.912\n",
      "Best features are for number  9  are:  Index(['Cruise_line', 'Age', 'cabins', 'crew', 'passengers', 'length',\n",
      "       'length_per_cabin', 'passengers_per_length', 'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 13.156\n",
      "Best features are for number  10  are:  Index(['Cruise_line', 'Age', 'cabins', 'crew', 'passengers', 'length',\n",
      "       'passenger_per_cabin', 'length_per_cabin', 'passengers_per_length',\n",
      "       'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 13.279\n",
      "Best features are for number  11  are:  Index(['Cruise_line', 'Age', 'cabins', 'crew', 'passengers', 'length',\n",
      "       'passenger_density', 'passenger_per_cabin', 'length_per_cabin',\n",
      "       'passengers_per_length', 'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 13.142\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest\")\n",
    "\n",
    "for i in range(1, 12):\n",
    "\n",
    "\tX_train_fs, X_val_fs, fs = select_features(X_train, y_train, X_val, i)\n",
    "\n",
    "\tmodel = RandomForestRegressor()\n",
    "\tmodel.fit(X_train_fs, y_train)\n",
    "\n",
    "\tyhat = model.predict(X_val_fs)\n",
    "\n",
    "\t# Get the names of the features\n",
    "\tfilter = fs.get_support()\n",
    "\tfeatures = X_train.columns\n",
    "\n",
    "\tprint(\"Best features are for number \", i, \" are: \", features[filter])\n",
    "\trmse = mean_squared_error(y_val, yhat, squared=False)\n",
    "\tprint('RMSE: %.3f' % rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performance RF: 7 features, followed by 6 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "Best features are for number  1  are:  Index(['total_people'], dtype='object')\n",
      "RMSE: 16.412\n",
      "Best features are for number  2  are:  Index(['passengers', 'total_people'], dtype='object')\n",
      "RMSE: 14.974\n",
      "Best features are for number  3  are:  Index(['cabins', 'passengers', 'total_people'], dtype='object')\n",
      "RMSE: 14.861\n",
      "Best features are for number  4  are:  Index(['cabins', 'passengers', 'length', 'total_people'], dtype='object')\n",
      "RMSE: 12.546\n",
      "Best features are for number  5  are:  Index(['cabins', 'crew', 'passengers', 'length', 'total_people'], dtype='object')\n",
      "RMSE: 12.600\n",
      "Best features are for number  6  are:  Index(['cabins', 'crew', 'passengers', 'length', 'length_per_cabin',\n",
      "       'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 12.722\n",
      "Best features are for number  7  are:  Index(['cabins', 'crew', 'passengers', 'length', 'length_per_cabin',\n",
      "       'passengers_per_length', 'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 13.545\n",
      "Best features are for number  8  are:  Index(['Age', 'cabins', 'crew', 'passengers', 'length', 'length_per_cabin',\n",
      "       'passengers_per_length', 'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 12.685\n",
      "Best features are for number  9  are:  Index(['Cruise_line', 'Age', 'cabins', 'crew', 'passengers', 'length',\n",
      "       'length_per_cabin', 'passengers_per_length', 'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 12.846\n",
      "Best features are for number  10  are:  Index(['Cruise_line', 'Age', 'cabins', 'crew', 'passengers', 'length',\n",
      "       'passenger_per_cabin', 'length_per_cabin', 'passengers_per_length',\n",
      "       'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 12.433\n",
      "Best features are for number  11  are:  Index(['Cruise_line', 'Age', 'cabins', 'crew', 'passengers', 'length',\n",
      "       'passenger_density', 'passenger_per_cabin', 'length_per_cabin',\n",
      "       'passengers_per_length', 'total_people'],\n",
      "      dtype='object')\n",
      "RMSE: 12.465\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient Boosting\")\n",
    "\n",
    "for i in range(1, 12):\n",
    "\n",
    "\tX_train_fs, X_val_fs, fs = select_features(X_train, y_train, X_val, i)\n",
    "\n",
    "\tmodel = GradientBoostingRegressor()\n",
    "\tmodel.fit(X_train_fs, y_train)\n",
    "\n",
    "\tyhat = model.predict(X_val_fs)\n",
    "\n",
    "\t# Get the names of the features\n",
    "\tfilter = fs.get_support()\n",
    "\tfeatures = X_train.columns\n",
    "\n",
    "\tprint(\"Best features are for number \", i, \" are: \", features[filter])\n",
    "\trmse = mean_squared_error(y_val, yhat, squared=False)\n",
    "\tprint('RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performance GB: 4 features, followed by 11 features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all models perform better with a different subset of features. RF and GB with a lower number of features, LR with a higher number of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual subset testing\n",
    "To explore the features further, I tried manual feature combinations. \n",
    "\n",
    "- Exclude Age and Cruiseline\n",
    "- Exclude passenger_per_length and passengers\n",
    "- Exclude crew and length_per_cabin \n",
    "\n",
    "I tried these removals. The first one I based on the earlier investigation using the importance of the models tried. The last four are features that were already embedded in other features (passengers and crew can be found in total_people) and they also scored low on the feature importance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression\n",
      "MAE LR: 4.043\n",
      "R2 LR: 0.984\n",
      "RMSE LR: 5.584\n",
      "Random forest\n",
      "MAE RF: 5.434\n",
      "R2 RF: 0.905\n",
      "RMSE RF: 13.456\n",
      "Gradient Boosting\n",
      "MAE GB: 4.709\n",
      "R2 GB: 0.917\n",
      "RMSE GB: 12.574\n"
     ]
    }
   ],
   "source": [
    "# Baseline all features \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "print(\"Linear regression\")\n",
    "# Linear Regression \n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_val)\n",
    "\n",
    "mae = mean_absolute_error(y_val, yhat)\n",
    "r2 = r2_score(y_val, yhat)\n",
    "rmse = mean_squared_error(y_val, yhat, squared=False)\n",
    "print('MAE LR: %.3f' % mae)\n",
    "print('R2 LR: %.3f' % r2)\n",
    "print('RMSE LR: %.3f' % rmse)\n",
    "\n",
    "print(\"Random forest\")\n",
    "# Random Forest\n",
    "model2 = RandomForestRegressor()\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "yhat2 = model2.predict(X_val)\n",
    "\n",
    "mae2 = mean_absolute_error(y_val, yhat2)\n",
    "r2_2 = r2_score(y_val, yhat2)\n",
    "rmse2 = mean_squared_error(y_val, yhat2, squared = False)\n",
    "print('MAE RF: %.3f' % mae2)\n",
    "print('R2 RF: %.3f' % r2_2)\n",
    "print('RMSE RF: %.3f' % rmse2)\n",
    "\n",
    "# Gradient Boosting \n",
    "print(\"Gradient Boosting\")\n",
    "reg = GradientBoostingRegressor(random_state=0)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "yhat_gb= reg.predict(X_val)\n",
    "\n",
    "mae_gb = mean_absolute_error(y_val, yhat_gb)\n",
    "r2_gb = r2_score(y_val, yhat_gb)\n",
    "rmse_gb = mean_squared_error(y_val, yhat_gb, squared = False)\n",
    "print('MAE GB: %.3f' % mae_gb)\n",
    "print('R2 GB: %.3f' % r2_gb)\n",
    "print('RMSE GB: %.3f' % rmse_gb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude Age and Cruiseline \n",
    "subset_X_train = X_train[['cabins', 'crew', 'passengers', 'length',\n",
    "       'passenger_density', 'passenger_per_cabin', 'length_per_cabin',\n",
    "       'passengers_per_length', 'total_people']]\n",
    "    \n",
    "subset_X_val = X_val[['cabins', 'crew', 'passengers', 'length',\n",
    "       'passenger_density', 'passenger_per_cabin', 'length_per_cabin',\n",
    "       'passengers_per_length', 'total_people']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "MAE LR_sub: 3.899\n",
      "R2 LR_sub: 0.984\n",
      "RMSE LR_sub: 5.279\n",
      "Random Forest\n",
      "MAE RF_sub: 5.112\n",
      "R2 RF_sub: 0.906\n",
      "RMSE RF_sub: 13.384\n",
      "Gradient boosting\n",
      "MAE GB_sub: 4.613\n",
      "R2 GB_sub: 0.923\n",
      "RMSE GB_sub: 12.168\n"
     ]
    }
   ],
   "source": [
    "# Exclude age and cruiseline\n",
    "# Linear Regression \n",
    "print('Linear Regression')\n",
    "modelsub = LinearRegression()\n",
    "modelsub.fit(subset_X_train, y_train)\n",
    "\n",
    "yhat_sub = modelsub.predict(subset_X_val)\n",
    "\n",
    "mae_sub = mean_absolute_error(y_val, yhat_sub)\n",
    "r2_sub = r2_score(y_val, yhat)\n",
    "rmse_sub = mean_squared_error(y_val, yhat_sub, squared=False)\n",
    "print('MAE LR_sub: %.3f' % mae_sub)\n",
    "print('R2 LR_sub: %.3f' % r2_sub)\n",
    "print('RMSE LR_sub: %.3f' % rmse_sub)\n",
    "\n",
    "# Random Forest\n",
    "print(\"Random Forest\")\n",
    "model2_sub = RandomForestRegressor()\n",
    "model2_sub.fit(subset_X_train, y_train)\n",
    "\n",
    "yhat2_sub = model2_sub.predict(subset_X_val)\n",
    "\n",
    "mae2_sub = mean_absolute_error(y_val, yhat2_sub)\n",
    "r2_2_sub = r2_score(y_val, yhat2_sub)\n",
    "rmse2_sub = mean_squared_error(y_val, yhat2_sub, squared = False)\n",
    "print('MAE RF_sub: %.3f' % mae2_sub)\n",
    "print('R2 RF_sub: %.3f' % r2_2_sub)\n",
    "print('RMSE RF_sub: %.3f' % rmse2_sub)\n",
    "\n",
    "# gradient boosting \n",
    "print(\"Gradient boosting\")\n",
    "reg_sub = GradientBoostingRegressor(random_state=0)\n",
    "reg_sub.fit(subset_X_train, y_train)\n",
    "\n",
    "yhat_gb_sub= reg_sub.predict(subset_X_val)\n",
    "\n",
    "mae_gb_sub = mean_absolute_error(y_val, yhat_gb_sub)\n",
    "r2_gb_sub = r2_score(y_val, yhat_gb_sub)\n",
    "rmse_gb_sub = mean_squared_error(y_val, yhat_gb_sub, squared = False)\n",
    "print('MAE GB_sub: %.3f' % mae_gb_sub)\n",
    "print('R2 GB_sub: %.3f' % r2_gb_sub)\n",
    "print('RMSE GB_sub: %.3f' % rmse_gb_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude passenger_per_cabin and crew \n",
    "subset_X_train = X_train[['cabins', 'passengers', 'length',\n",
    "       'passenger_density', 'length_per_cabin',\n",
    "       'passengers_per_length', 'total_people']]\n",
    "    \n",
    "subset_X_val = X_val[['cabins' , 'passengers', 'length',\n",
    "       'passenger_density','length_per_cabin',\n",
    "       'passengers_per_length', 'total_people']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "MAE LR_sub: 3.915\n",
      "R2 LR_sub: 0.984\n",
      "RMSE LR_sub: 5.556\n",
      "Random Forest\n",
      "MAE RF_sub: 5.226\n",
      "R2 RF_sub: 0.909\n",
      "RMSE RF_sub: 13.162\n",
      "Gradient boosting\n",
      "MAE GB_sub: 4.544\n",
      "R2 GB_sub: 0.919\n",
      "RMSE GB_sub: 12.413\n"
     ]
    }
   ],
   "source": [
    "# Exclude passenger_per_cabin and crew \n",
    "# Linear Regression \n",
    "print('Linear Regression')\n",
    "\n",
    "modelsub = LinearRegression()\n",
    "modelsub.fit(subset_X_train, y_train)\n",
    "\n",
    "yhat_sub = modelsub.predict(subset_X_val)\n",
    "\n",
    "mae_sub = mean_absolute_error(y_val, yhat_sub)\n",
    "r2_sub = r2_score(y_val, yhat)\n",
    "rmse_sub = mean_squared_error(y_val, yhat_sub, squared=False)\n",
    "print('MAE LR_sub: %.3f' % mae_sub)\n",
    "print('R2 LR_sub: %.3f' % r2_sub)\n",
    "print('RMSE LR_sub: %.3f' % rmse_sub)\n",
    "\n",
    "# Random Forest\n",
    "print(\"Random Forest\")\n",
    "\n",
    "model2_sub = RandomForestRegressor()\n",
    "model2_sub.fit(subset_X_train, y_train)\n",
    "\n",
    "yhat2_sub = model2_sub.predict(subset_X_val)\n",
    "\n",
    "mae2_sub = mean_absolute_error(y_val, yhat2_sub)\n",
    "r2_2_sub = r2_score(y_val, yhat2_sub)\n",
    "rmse2_sub = mean_squared_error(y_val, yhat2_sub, squared = False)\n",
    "print('MAE RF_sub: %.3f' % mae2_sub)\n",
    "print('R2 RF_sub: %.3f' % r2_2_sub)\n",
    "print('RMSE RF_sub: %.3f' % rmse2_sub)\n",
    "\n",
    "# gradient boosting \n",
    "print(\"Gradient boosting\")\n",
    "reg_sub = GradientBoostingRegressor(random_state=0)\n",
    "reg_sub.fit(subset_X_train, y_train)\n",
    "\n",
    "yhat_gb_sub= reg_sub.predict(subset_X_val)\n",
    "\n",
    "mae_gb_sub = mean_absolute_error(y_val, yhat_gb_sub)\n",
    "r2_gb_sub = r2_score(y_val, yhat_gb_sub)\n",
    "rmse_gb_sub = mean_squared_error(y_val, yhat_gb_sub, squared = False)\n",
    "print('MAE GB_sub: %.3f' % mae_gb_sub)\n",
    "print('R2 GB_sub: %.3f' % r2_gb_sub)\n",
    "print('RMSE GB_sub: %.3f' % rmse_gb_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude passenger_per_length and passengers\n",
    "subset_X_train = X_train[['cabins',  'length', 'passenger_density',\n",
    "        'length_per_cabin', 'total_people']]\n",
    "    \n",
    "subset_X_val = X_val[['cabins' ,  'length', 'passenger_density',\n",
    "       'length_per_cabin', 'total_people']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "MAE LR_sub: 3.899\n",
      "R2 LR_sub: 0.984\n",
      "RMSE LR_sub: 5.279\n",
      "Random Forest\n",
      "MAE RF_sub: 4.625\n",
      "R2 RF_sub: 0.916\n",
      "RMSE RF_sub: 12.690\n",
      "Gradient boosting\n",
      "MAE GB_sub: 4.613\n",
      "R2 GB_sub: 0.923\n",
      "RMSE GB_sub: 12.168\n"
     ]
    }
   ],
   "source": [
    "# Exclude passenger per length and passengers\n",
    "# Linear Regression \n",
    "print('Linear Regression')\n",
    "\n",
    "modelsub = LinearRegression()\n",
    "modelsub.fit(subset_X_train, y_train)\n",
    "\n",
    "yhat_sub = modelsub.predict(subset_X_val)\n",
    "\n",
    "mae_sub = mean_absolute_error(y_val, yhat_sub)\n",
    "r2_sub = r2_score(y_val, yhat)\n",
    "rmse_sub = mean_squared_error(y_val, yhat_sub, squared=False)\n",
    "print('MAE LR_sub: %.3f' % mae_sub)\n",
    "print('R2 LR_sub: %.3f' % r2_sub)\n",
    "print('RMSE LR_sub: %.3f' % rmse_sub)\n",
    "\n",
    "# Random Forest\n",
    "print(\"Random Forest\")\n",
    "\n",
    "model2_sub = RandomForestRegressor()\n",
    "model2_sub.fit(subset_X_train, y_train)\n",
    "\n",
    "yhat2_sub = model2_sub.predict(subset_X_val)\n",
    "\n",
    "mae2_sub = mean_absolute_error(y_val, yhat2_sub)\n",
    "r2_2_sub = r2_score(y_val, yhat2_sub)\n",
    "rmse2_sub = mean_squared_error(y_val, yhat2_sub, squared = False)\n",
    "print('MAE RF_sub: %.3f' % mae2_sub)\n",
    "print('R2 RF_sub: %.3f' % r2_2_sub)\n",
    "print('RMSE RF_sub: %.3f' % rmse2_sub)\n",
    "\n",
    "# gradient boosting \n",
    "print(\"Gradient boosting\")\n",
    "reg_sub = GradientBoostingRegressor(random_state=0)\n",
    "reg_sub.fit(subset_X_train, y_train)\n",
    "\n",
    "yhat_gb_sub= reg_sub.predict(subset_X_val)\n",
    "\n",
    "mae_gb_sub = mean_absolute_error(y_val, yhat_gb_sub)\n",
    "r2_gb_sub = r2_score(y_val, yhat_gb_sub)\n",
    "rmse_gb_sub = mean_squared_error(y_val, yhat_gb_sub, squared = False)\n",
    "print('MAE GB_sub: %.3f' % mae_gb_sub)\n",
    "print('R2 GB_sub: %.3f' % r2_gb_sub)\n",
    "print('RMSE GB_sub: %.3f' % rmse_gb_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After manual feature deletion, I have found that 5 features instead of 11 are sufficient for prediction: 'cabins',  'length', 'passenger_density', 'length_per_cabin', 'total_people'. I tried every exclusion of features with and without previously removed features. So for example, I tried inserting 'Cruise_line' and 'Age'  when I removed 'passenger_per_length'  and 'passengers'. This is my final verdict of important features: 3 already existing features and 2 manual features. \n",
    "\n",
    "As the dataset is not that large, I did not expect a large number of features. In comparison with the manual feature select of SelectKBest, other features are selected as most important for some algorithms. LR shows best performance using 10 features, GB using 4 features and RF using 6 features. I tried these features manually as well, but this shows a decrease in R2 score. As performance between the models differs and the optimal number of features differ as well using SelectKBest, I will keep the 5 manually selected features for the hyperparameter tuning of the final models as the performance seems to be better than with SelectKBest. It would be interesting to compare final performance with manual selected features vs. SelectKBest, but this would mean 3 x 2 hyperparameter tuning processes, so in this case I will keep it with the manual investigation and results. \n",
    "\n",
    "The feature passenger_density scored low in the earlier investigation of feature importance. But I tried removing this as well, but it does not work in combination with total_feature and removal of passengers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of X_train, X_val and X_test\n",
    "subset_X_train = X_train[['cabins',  'length', 'passenger_density',\n",
    "        'length_per_cabin', 'total_people']]\n",
    "    \n",
    "subset_X_val = X_val[['cabins' ,  'length', 'passenger_density',\n",
    "       'length_per_cabin', 'total_people']]\n",
    "\n",
    "subset_X_test = X_test[['cabins' ,  'length', 'passenger_density',\n",
    "       'length_per_cabin', 'total_people']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Choose algorithm for the regression task  and hyperparameter tuning\n",
    "The algorithm of choice is determined by cross validation. The models compared are Linear Regression, Random Forests and Gradient Boosting. The baseline performance is the performance of the untuned models for the feature selection, shown underneath each model. I use the RandomizedSearchCV of sklearn, because this allows for K-Fold cross validation in a randomized way. It will select at random which values for the parameters will be sampled. \n",
    "\n",
    "### Linear regression \n",
    "As the data might be linear, Linear Regression would work fine by the KISS principle: keep it simple stupid. Why use a complex model that is more difficult to explain if we can also use a very simple model that is easy to interpret?\n",
    "\n",
    "- MAE LR_sub: 3.899\n",
    "- R2 LR_sub: 0.984\n",
    "- RMSE LR_sub: 5.279\n",
    "\n",
    "I found out that I cannot tune LR. I did not know this, but then the baseline is the final model. \n",
    "\n",
    "### Random Forests:\n",
    "The Random Forest creates different Decision trees (ensemble of decision trees) and takes the average prediction. However, it cannot extrapolate, meaning that it is not able to obtain values outside ethe train set during prediction. It is not the best model when the data is linear. \n",
    "\n",
    "- MAE RF_sub: 4.625\n",
    "- R2 RF_sub: 0.916\n",
    "- RMSE RF_sub: 12.690\n",
    "\n",
    "The parameters I will tune are:\n",
    "- n_estimators: number of trees\n",
    "- max_features: the max number of features that are considered for each split\n",
    "- max_depth: maximum number of levels in a tree\n",
    "- min_samples_split: the minimum number of data points necessary for a split\n",
    "- min_samples_leaf: the minimum number of data points allowed in a leaf\n",
    "- bootstrap: whether to sample the data points or use it all \n",
    "\n",
    "### Gradient Boosting:\n",
    "The last model is Gradient boosting \n",
    "\n",
    "- MAE GB_sub: 4.613\n",
    "- R2 GB_sub: 0.923\n",
    "- RMSE GB_sub: 12.168\n",
    "\n",
    "### Measurements\n",
    "The model will be evaluated using Root Mean Squared Error and the R2 score. These metrics provide a baseline which we try to improve with hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(subset_X_train, y_train)\n",
    "\n",
    "lr_yhat = lr.predict(subset_X_val)\n",
    "\n",
    "r2_lr = r2_score(y_val, lr_yhat)\n",
    "rmse_lr = mean_squared_error(y_val, lr_yhat, squared=False)\n",
    "print('R2 LR: %.3f' % r2_lr)\n",
    "print('RMSE LR: %.3f' % rmse_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest tuning\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "rf_grid = {'bootstrap': [True, False],\n",
    "               'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
    "               'max_features': ['auto', 'sqrt', 1,2,3,4,5],\n",
    "               'min_samples_leaf': [1, 2, 3, 4, 8, 10, ],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'n_estimators': [1,2,4,8,16,32,40, 50, 64,100, 120, 140, 150, 200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual search\n",
    "\n",
    "rf_search = RandomizedSearchCV(rf, rf_grid, n_iter=100, scoring = 'neg_root_mean_squared_error', cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the train set \n",
    "rf_model = rf_search.fit(subset_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'squared_error',\n",
      " 'max_depth': 90,\n",
      " 'max_features': 4,\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 50,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Print the parameters \n",
    "pprint(rf_model.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 rf: 0.912\n",
      "RMSE rf: 12.999\n"
     ]
    }
   ],
   "source": [
    "# Test the model with the validation set \n",
    "rf_yhat = rf_model.predict(subset_X_val)\n",
    "\n",
    "r2_rf = r2_score(y_val, rf_yhat)\n",
    "rmse_rf = mean_squared_error(y_val, rf_yhat, squared = False)\n",
    "print('R2 rf: %.3f' % r2_rf)\n",
    "print('RMSE rf: %.3f' % rmse_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GB tuning \n",
    "\n",
    "gb = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with the validation set\n",
    "\n",
    "gb_yhat = gb_model.predict(subset_X_val)\n",
    "\n",
    "r2_gb = r2_score(y_val, gb_yhat)\n",
    "rmse_gb = mean_squared_error(y_val, gb_yhat, squared = False)\n",
    "print('R2 rf: %.3f' % r2_gb)\n",
    "print('RMSE rf: %.3f' % rmse_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7a: Testing per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr_yhat_test = lr.predict(subset_X_test)\n",
    "\n",
    "r2_lr = r2_score(y_test, lr_yhat_test)\n",
    "rmse_lr = mean_squared_error(y_test, lr_yhat_test, squared=False)\n",
    "print('R2 LR: %.3f' % r2_lr)\n",
    "print('RMSE LR: %.3f' % rmse_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 rf: 0.500\n",
      "RMSE rf: 17.102\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "rf_yhat_test = rf_model.predict(subset_X_test)\n",
    "\n",
    "r2_rf = r2_score(y_test, rf_yhat_test)\n",
    "rmse_rf = mean_squared_error(y_test, rf_yhat_test, squared = False)\n",
    "print('R2 rf: %.3f' % r2_rf)\n",
    "print('RMSE rf: %.3f' % rmse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "gb_yhat_test = gb_model.predict(subset_X_test)\n",
    "\n",
    "r2_gb = r2_score(y_test, gb_yhat_test)\n",
    "rmse_gb = mean_squared_error(y_test, gb_yhat_test, squared = False)\n",
    "print('R2 rf: %.3f' % r2_gb)\n",
    "print('RMSE rf: %.3f' % rmse_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7b: compare with passengers * passenger_density \n",
    "\n",
    "As I went through the column names, I did not know what \"passenger_density was\". When I looked it up online, I got the feeling that (passenger * passenger_density) / 10 is the gross tonnage. I tried this for a few values in Excell, so I will make predictions using only these 2 and compare this against the test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66     15.66\n",
      "9      37.00\n",
      "118     7.00\n",
      "85     20.02\n",
      "Name: passengers, dtype: float64\n",
      "66      58.59972\n",
      "9      110.22300\n",
      "118     45.99700\n",
      "85      77.09702\n",
      "dtype: float64\n",
      "66      58.600\n",
      "9      110.239\n",
      "118     46.000\n",
      "85      77.104\n",
      "Name: gross_tonnage, dtype: float64\n",
      "RMSE manual: 0.009\n"
     ]
    }
   ],
   "source": [
    "y_manual_prediction = (X_test[\"passengers\"] * X_test[\"passenger_density\"])/10\n",
    "\n",
    "r2_manual = r2_score(y_test, y_manual_prediction)\n",
    "rmse_manual = mean_squared_error(y_test, y_manual_prediction, squared = False)\n",
    "\n",
    "print(y_manual_prediction)\n",
    "print(y_test)\n",
    "\n",
    "print('RMSE manual: %.3f' % rmse_manual)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "810c3cea8ecd37a42d1c099cfb4835b3206c99d90dfa161a9a30fa0ee2de1394"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('ddg': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
